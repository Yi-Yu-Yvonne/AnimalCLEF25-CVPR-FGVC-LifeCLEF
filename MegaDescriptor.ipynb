{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7db823",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "596e9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: timm in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: numpy in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: wildlife-datasets in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (1.0.6)\n",
      "Requirement already satisfied: tqdm in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: pyyaml in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from timm) (0.30.2)\n",
      "Requirement already satisfied: safetensors in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.62 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from wildlife-datasets) (4.11.0.86)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from wildlife-datasets) (2.0.8)\n",
      "Requirement already satisfied: datasets in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from wildlife-datasets) (3.5.0)\n",
      "Requirement already satisfied: gdown in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from wildlife-datasets) (5.2.0)\n",
      "Requirement already satisfied: kaggle in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from wildlife-datasets) (1.7.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from datasets->wildlife-datasets) (3.11.18)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from gdown->wildlife-datasets) (4.13.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: bleach in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (3.4.1)\n",
      "Requirement already satisfied: idna in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (3.10)\n",
      "Requirement already satisfied: protobuf in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (6.30.2)\n",
      "Requirement already satisfied: python-slugify in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (8.0.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (65.5.0)\n",
      "Requirement already satisfied: text-unidecode in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from kaggle->wildlife-datasets) (0.5.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from aiohttp->datasets->wildlife-datasets) (1.20.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from beautifulsoup4->gdown->wildlife-datasets) (2.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/intern/Yu/animalvenv/lib/python3.11/site-packages (from requests[socks]->gdown->wildlife-datasets) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio timm numpy scikit-learn matplotlib pandas wildlife-datasets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9c64432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import AutoModel\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdd8b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local environment\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if running in Kaggle or Colab\n",
    "IN_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    print(\"Running in Kaggle\")\n",
    "    # Set data path\n",
    "    DATA_PATH = '/kaggle/input/animal-clef-2025'\n",
    "elif IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Mount Google Drive if in Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Install required packages\n",
    "    !pip install -q git+https://github.com/WildlifeDatasets/wildlife-datasets@develop\n",
    "    !pip install -q git+https://github.com/WildlifeDatasets/wildlife-tools\n",
    "    !pip install -q timm transformers\n",
    "# Set data path\n",
    "    DATA_PATH = '/content/drive/MyDrive/5524_CVEVAN/animal-clef-2025'\n",
    "else:\n",
    "    print(\"Running in local environment\")\n",
    "    # Set appropriate path for your environment\n",
    "    DATA_PATH = './animal-clef-2025'\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635583b",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14174643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (15209, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "      <th>orientation</th>\n",
       "      <th>species</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LynxID2025_lynx_37</td>\n",
       "      <td>images/LynxID2025/database/000f9ee1aad063a4485...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>lynx</td>\n",
       "      <td>database</td>\n",
       "      <td>LynxID2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LynxID2025_lynx_37</td>\n",
       "      <td>images/LynxID2025/database/0020edb6689e9f78462...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>lynx</td>\n",
       "      <td>database</td>\n",
       "      <td>LynxID2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LynxID2025_lynx_49</td>\n",
       "      <td>images/LynxID2025/database/003152e4145b5b69400...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>lynx</td>\n",
       "      <td>database</td>\n",
       "      <td>LynxID2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/LynxID2025/query/003b89301c7b9f6d18f722...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>back</td>\n",
       "      <td>lynx</td>\n",
       "      <td>query</td>\n",
       "      <td>LynxID2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LynxID2025_lynx_13</td>\n",
       "      <td>images/LynxID2025/database/003c3f82011e9c3f849...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>lynx</td>\n",
       "      <td>database</td>\n",
       "      <td>LynxID2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id            identity  \\\n",
       "0         0  LynxID2025_lynx_37   \n",
       "1         1  LynxID2025_lynx_37   \n",
       "2         2  LynxID2025_lynx_49   \n",
       "3         3                 NaN   \n",
       "4         4  LynxID2025_lynx_13   \n",
       "\n",
       "                                                path date orientation species  \\\n",
       "0  images/LynxID2025/database/000f9ee1aad063a4485...  NaN       right    lynx   \n",
       "1  images/LynxID2025/database/0020edb6689e9f78462...  NaN        left    lynx   \n",
       "2  images/LynxID2025/database/003152e4145b5b69400...  NaN        left    lynx   \n",
       "3  images/LynxID2025/query/003b89301c7b9f6d18f722...  NaN        back    lynx   \n",
       "4  images/LynxID2025/database/003c3f82011e9c3f849...  NaN       right    lynx   \n",
       "\n",
       "      split     dataset  \n",
       "0  database  LynxID2025  \n",
       "1  database  LynxID2025  \n",
       "2  database  LynxID2025  \n",
       "3     query  LynxID2025  \n",
       "4  database  LynxID2025  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv(os.path.join(DATA_PATH, 'metadata.csv'))\n",
    "print(f\"Metadata shape: {metadata.shape}\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d19aaf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 15209\n",
      "Database images: 13074\n",
      "Query images: 2135\n",
      "\n",
      "Species distribution:\n",
      "species\n",
      "loggerhead turtle    9229\n",
      "lynx                 3903\n",
      "salamander            689\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique individuals: 1102\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Explore dataset statistics\n",
    "print(f\"Total images: {len(metadata)}\")\n",
    "print(f\"Database images: {len(metadata[metadata['split'] == 'database'])}\")\n",
    "print(f\"Query images: {len(metadata[metadata['split'] == 'query'])}\")\n",
    "\n",
    "# Count species\n",
    "species_counts = metadata['species'].value_counts()\n",
    "print(\"\\nSpecies distribution:\")\n",
    "print(species_counts)\n",
    "\n",
    "# Visualize species distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=species_counts.index, y=species_counts.values)\n",
    "plt.title('Species Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count unique individuals\n",
    "unique_individuals = metadata[metadata['identity'].notna()]['identity'].nunique()\n",
    "print(f\"\\nNumber of unique individuals: {unique_individuals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d2b4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "\n",
    "# Create custom dataset class\n",
    "class AnimalReIDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, metadata, root_dir, transform=None, split='database'):\n",
    "        self.metadata = metadata[metadata['split'] == split].reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "\n",
    "        # Create label mapping for identities\n",
    "        if split in ['database', 'train']:\n",
    "            self.identities = sorted(self.metadata['identity'].dropna().unique())\n",
    "            self.identity_to_idx = {identity: idx for idx, identity in enumerate(self.identities)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row['path'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # For database images, return image, identity index, and identity\n",
    "        # if self.metadata['split'].iloc[0] == 'database':\n",
    "        if self.split in ['database', 'train']:\n",
    "            identity = row['identity']\n",
    "            if pd.isna(identity):\n",
    "                identity_idx = -1  # For images without identity\n",
    "            else:\n",
    "                identity_idx = self.identity_to_idx[identity]\n",
    "            return image, identity_idx, identity\n",
    "        # For query images, return image and image_id\n",
    "        else:\n",
    "            return image, row['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f4eea",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction and Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cd497dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from database images\n",
    "def extract_database_embeddings(model, data_loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    identities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _, identity in tqdm(data_loader, desc='Extracting database embeddings'):\n",
    "            images = images.to(device)\n",
    "            batch_embeddings = model(images)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            identities.extend(identity)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings, identities\n",
    "\n",
    "# Extract embeddings from query images\n",
    "def extract_query_embeddings(model, data_loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, ids in tqdm(data_loader, desc='Extracting query embeddings'):\n",
    "            images = images.to(device)\n",
    "            batch_embeddings = model(images)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            image_ids.extend(ids.numpy())\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings, image_ids\n",
    "\n",
    "# Perform retrieval using k-nearest neighbors\n",
    "def perform_retrieval(db_embeddings, query_embeddings, db_identities, query_ids, k=5, threshold=0.7):\n",
    "    # Initialize k-nearest neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=min(k, len(db_embeddings)), metric='cosine')\n",
    "    knn.fit(db_embeddings)\n",
    "\n",
    "    # Find k-nearest neighbors for each query\n",
    "    distances, indices = knn.kneighbors(query_embeddings)\n",
    "\n",
    "    # Convert distances to similarities (1 - distance)\n",
    "    similarities = 1 - distances\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = []\n",
    "    for i, (sims, idxs) in enumerate(zip(similarities, indices)):\n",
    "        query_id = query_ids[i]\n",
    "\n",
    "        # Check if the highest similarity is above threshold\n",
    "        if sims[0] > threshold:\n",
    "            # Predict the identity of the most similar database image\n",
    "            prediction = db_identities[idxs[0]]\n",
    "        else:\n",
    "            # Predict as new individual\n",
    "            prediction = 'new_individual'\n",
    "\n",
    "        predictions.append({'image_id': int(query_id), 'prediction': prediction})\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb308abc",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e91de818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "def evaluate_predictions(predictions, ground_truths):\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics for the predictions\n",
    "\n",
    "    Args:\n",
    "        predictions: List of predicted identities\n",
    "        ground_truths: List of ground truth identities\n",
    "\n",
    "    Returns:\n",
    "        metrics: Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    # Convert predictions and ground truths to binary format for metrics calculation\n",
    "    # 1 for known individual, 0 for new individual\n",
    "    y_pred_binary = [0 if p == 'new_individual' else 1 for p in predictions]\n",
    "    y_true_binary = [0 if gt == 'new_individual' else 1 for gt in ground_truths]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "    # Calculate identity accuracy for known individuals\n",
    "    known_indices = [i for i, gt in enumerate(ground_truths) if gt != 'new_individual']\n",
    "    if known_indices:\n",
    "        known_predictions = [predictions[i] for i in known_indices]\n",
    "        known_ground_truths = [ground_truths[i] for i in known_indices]\n",
    "        identity_accuracy = sum(p == gt for p, gt in zip(known_predictions, known_ground_truths)) / len(known_indices)\n",
    "    else:\n",
    "        identity_accuracy = 0.0\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'identity_accuracy': identity_accuracy\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f026ba",
   "metadata": {},
   "source": [
    "## 6. Main Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b697c0",
   "metadata": {},
   "source": [
    "### 6.1 Divide into train & val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63cc959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "database    13074\n",
       "query        2135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4b29f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    11766\n",
       "query     2135\n",
       "val       1308\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['orig_split'] = metadata['split']\n",
    "\n",
    "# divide split['database'] to train and val dataset\n",
    "database_df = metadata[metadata['split'] == 'database'].copy()\n",
    "train_df, val_df = train_test_split(database_df, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "metadata.loc[train_df.index, 'split'] = 'train'\n",
    "metadata.loc[val_df.index, 'split'] = 'val'\n",
    "metadata['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aaec7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Define image transformations\n",
    "# Image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# construct dataset\n",
    "db_dataset = AnimalReIDDataset(metadata, DATA_PATH, transform, split='train')\n",
    "val_dataset   = AnimalReIDDataset(metadata, DATA_PATH, transform, split='val')\n",
    "query_dataset = AnimalReIDDataset(metadata, DATA_PATH, transform, split='query')\n",
    "\n",
    "# dataLoader\n",
    "db_loader = torch.utils.data.DataLoader(db_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d54c4",
   "metadata": {},
   "source": [
    "### 6.2 Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c10c4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 1061\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "num_classes = len(db_dataset.identities) if hasattr(db_dataset, 'identities') else 0\n",
    "print(f\"Number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52360a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"hf-hub:BVRA/MegaDescriptor-L-384\", pretrained=True)\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9636a",
   "metadata": {},
   "source": [
    "### 6.3 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8dcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings using ResNet50\n",
    "print(\"Extracting MegaDescriptor embeddings...\")\n",
    "mega_db_embeddings, mega_db_identities = extract_database_embeddings(model, db_loader)\n",
    "mega_query_embeddings, mega_query_ids = extract_query_embeddings(model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb327d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_val_embeddings, mega_val_ids = extract_query_embeddings(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380dbaa",
   "metadata": {},
   "source": [
    "### 6.4 Weight Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save embeddings to Google Drive if in Colab\n",
    "# if IN_COLAB:\n",
    "#     from google.colab import drive\n",
    "#     import os\n",
    "\n",
    "#     drive.mount('/content/drive')\n",
    "\n",
    "#     drive_path = './mega_embedding_id'\n",
    "#     os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "#     # Save MegaDescriptor embeddings\n",
    "#     np.save(drive_path + 'mega_db_embeddings.npy', mega_db_embeddings)\n",
    "#     np.save(drive_path + 'mega_query_embeddings.npy', mega_query_embeddings)\n",
    "#     np.save(drive_path + 'mega_db_identities.npy', mega_db_identities)\n",
    "#     np.save(drive_path + 'mega_query_ids.npy', mega_query_ids)\n",
    "#     np.save(drive_path + 'mega_val_embeddings.npy', mega_val_embeddings)\n",
    "#     np.save(drive_path + 'mega_val_ids.npy', mega_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac70060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved embeddings if available\n",
    "# Uncomment this section if you want to load previously saved embeddings\n",
    "drive_path = '/mega_embedding_id'\n",
    "if os.path.exists(drive_path + 'resnet_db_embeddings.npy'):\n",
    "    print(\"Loading saved embeddings from Google Drive...\")\n",
    "    mega_db_embeddings = np.load(drive_path + 'mega_db_embeddings.npy')\n",
    "    mega_query_embeddings = np.load(drive_path + 'mega_query_embeddings.npy')\n",
    "    mega_db_identities = np.load(drive_path + 'mega_db_identities.npy')\n",
    "    mega_query_ids = np.load(drive_path + 'mega_query_ids.npy')\n",
    "    mega_val_embeddings = np.load(drive_path + 'mega_val_embeddings.npy')\n",
    "    mega_val_ids = np.load(drive_path + 'mega_val_ids.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ebab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MegaDescriptor\n",
    "val_metadata = metadata[metadata[\"split\"] == \"val\"]\n",
    "query_metadata = metadata[metadata[\"split\"] == \"query\"]\n",
    "ground_truths = []\n",
    "for q_id in mega_val_ids:\n",
    "    row = val_metadata[val_metadata[\"image_id\"] == q_id].iloc[0]\n",
    "    gt = row[\"identity\"] if not pd.isna(row[\"identity\"]) else \"new_individual\"\n",
    "    ground_truths.append(gt)\n",
    "\n",
    "# print(\"Performing retrieval...\")\n",
    "val_results = []\n",
    "mega_threshold = 0.5\n",
    "predicted_identities = []\n",
    "\n",
    "db_matrix = torch.tensor(mega_db_embeddings)\n",
    "val_embed_tensor = torch.tensor(mega_val_embeddings)\n",
    "\n",
    "for q_idx in tqdm(range(len(mega_val_ids))):\n",
    "    q_id = mega_val_ids[q_idx]\n",
    "    q_embed = val_embed_tensor[q_idx].unsqueeze(0)\n",
    "\n",
    "    # cosine similarity\n",
    "    sims = F.cosine_similarity(q_embed, db_matrix, dim=1)\n",
    "\n",
    "    best_idx = torch.argmax(sims).item()\n",
    "    best_score = sims[best_idx].item()\n",
    "\n",
    "    if best_score > mega_threshold:\n",
    "        prediction = mega_db_identities[best_idx]\n",
    "    else:\n",
    "        prediction = \"new_individual\"\n",
    "\n",
    "    val_results.append([q_id, prediction])\n",
    "    predicted_identities.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Binary: known vs new\n",
    "y_true_binary = [0 if gt == \"new_individual\" else 1 for gt in ground_truths]\n",
    "y_pred_binary = [0 if pred == \"new_individual\" else 1 for pred in predicted_identities]\n",
    "\n",
    "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "# === identity accuracy (only for known individuals)\n",
    "known_indices = [i for i, gt in enumerate(ground_truths) if gt != \"new_individual\"]\n",
    "if known_indices:\n",
    "    correct = sum(predicted_identities[i] == ground_truths[i] for i in known_indices)\n",
    "    identity_acc = correct / len(known_indices)\n",
    "else:\n",
    "    identity_acc = 0.0\n",
    "\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(f\"New/Known Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Identity Accuracy (for known): {identity_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aed5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_open_set_metrics(ground_truths, predicted_identities, verbose=True):\n",
    "    \"\"\"\n",
    "    Computes BAKS, BAUS, and final geometric mean score for open-set individual identification.\n",
    "\n",
    "    Args:\n",
    "        ground_truths: List[str], ground truth identity (use \"new_individual\" for unknowns)\n",
    "        predicted_identities: List[str], predicted identity (use \"new_individual\" for unknowns)\n",
    "        verbose: bool, whether to print results\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with BAKS, BAUS, and geometric mean score\n",
    "    \"\"\"\n",
    "    known_gt_dict = defaultdict(list)\n",
    "    unknown_gt_list = []\n",
    "\n",
    "    for gt, pred in zip(ground_truths, predicted_identities):\n",
    "        if gt == \"new_individual\":\n",
    "            unknown_gt_list.append(pred == \"new_individual\")\n",
    "        else:\n",
    "            known_gt_dict[gt].append(pred == gt)\n",
    "\n",
    "    # Compute BAKS (per-class mean accuracy)\n",
    "    per_class_accs = [sum(results) / len(results) for results in known_gt_dict.values()]\n",
    "    baks = np.mean(per_class_accs) if per_class_accs else 0.0\n",
    "\n",
    "    # Compute BAUS (accuracy on unknowns)\n",
    "    baus = sum(unknown_gt_list) / len(unknown_gt_list) if unknown_gt_list else 0.0\n",
    "\n",
    "    # Geometric mean\n",
    "    final_score = np.sqrt(baks * baus)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n📊 Official Open-Set Evaluation:\")\n",
    "        print(f\"BAKS (Balanced Accuracy on Known Samples):   {baks:.4f}\")\n",
    "        print(f\"BAUS (Balanced Accuracy on Unknown Samples): {baus:.4f}\")\n",
    "        print(f\"Final Geometric Mean Score:                  {final_score:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"BAKS\": baks,\n",
    "        \"BAUS\": baus,\n",
    "        \"FinalScore\": final_score\n",
    "    }\n",
    "metrics = compute_open_set_metrics(ground_truths, predicted_identities)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform retrieval using MegaDescriptor with optimized threshold\n",
    "print(\"Performing retrieval using MegaDescriptor...\")\n",
    "mega_threshold = 0.5  # Slightly higher threshold for better precision\n",
    "mega_predictions = perform_retrieval(\n",
    "    mega_db_embeddings, mega_query_embeddings, mega_db_identities, mega_query_ids, k=5, threshold=mega_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52fa4e",
   "metadata": {},
   "source": [
    "## 7. Create Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4798fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MegaDescriptor submission file\n",
    "def create_submission_file(predictions, filename):\n",
    "    \"\"\"\n",
    "    Create a properly formatted submission file\n",
    "\n",
    "    Args:\n",
    "        predictions: List of prediction dictionaries with 'image_id' and 'prediction' keys\n",
    "        filename: Output filename for the submission CSV\n",
    "    \"\"\"\n",
    "    # Create submission dataframe with correct format\n",
    "    submission_df = pd.DataFrame()\n",
    "    submission_df['image_id'] = [pred['image_id'] for pred in predictions]\n",
    "    submission_df['identity'] = [pred['prediction'] for pred in predictions]\n",
    "\n",
    "    # Sort by image_id to ensure consistent order\n",
    "    submission_df = submission_df.sort_values('image_id').reset_index(drop=True)\n",
    "\n",
    "    # Verify that all query images are included\n",
    "    expected_query_ids = sorted(query_metadata['image_id'].values)\n",
    "    submission_ids = sorted(submission_df['image_id'].values)\n",
    "\n",
    "    if len(expected_query_ids) != len(submission_ids) or not all(a == b for a, b in zip(expected_query_ids, submission_ids)):\n",
    "        print(f\"WARNING: Submission doesn't contain all expected query IDs!\")\n",
    "        print(f\"Expected {len(expected_query_ids)} IDs, got {len(submission_ids)}\")\n",
    "\n",
    "        # Fix by creating a new dataframe with all expected IDs\n",
    "        fixed_submission = []\n",
    "        for query_id in expected_query_ids:\n",
    "            # Find the prediction for this query_id\n",
    "            match = next((pred for pred in predictions if pred['image_id'] == query_id), None)\n",
    "            if match:\n",
    "                fixed_submission.append({\n",
    "                    'image_id': query_id,\n",
    "                    'identity': match['prediction']\n",
    "                })\n",
    "            else:\n",
    "                # If no match found, use 'new_individual' as a fallback\n",
    "                fixed_submission.append({\n",
    "                    'image_id': query_id,\n",
    "                    'identity': 'new_individual'\n",
    "                })\n",
    "\n",
    "        submission_df = pd.DataFrame(fixed_submission)\n",
    "\n",
    "    # Save submission file\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nSubmission file saved to '{filename}'\")\n",
    "    print(f\"Submission shape: {submission_df.shape}\")\n",
    "    print(\"First few rows of submission:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "    return submission_df\n",
    "\n",
    "# Create Mega submission\n",
    "mega_submission = create_submission_file(mega_predictions, 'result/Mega_submission.csv')\n",
    "\n",
    "# Save in Google Drive if in Colab\n",
    "if IN_COLAB:\n",
    "    mega_submission.to_csv('/content/drive/MyDrive/5524_CVEVAN/Mega_submission.csv', index=False)\n",
    "    print(\"All submissions saved to Google Drive.\")\n",
    "\n",
    "    # Download the submission files\n",
    "    from google.colab import files\n",
    "    files.download('Mega_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Submit to Kaggle (uncomment to submit)\n",
    "# if IN_COLAB:\n",
    "#     # Submit ResNet50 model\n",
    "#     !kaggle competitions submit -c animal-clef-2025 -f resnet_submission.csv -m \"ResNet50 model with fixed submission format\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
